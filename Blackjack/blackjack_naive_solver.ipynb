{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Imports and installs\n",
    "'''\n",
    "%pip install gymnasium==0.27.0\n",
    "%pip install matplotlib\n",
    "%pip install numpy\n",
    "%pip install tqdm\n",
    "%matplotlib inline\n",
    "'''\n",
    "from collections import defaultdict #for accessing keys which are not present in dictionary\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "import sys\n",
    "import random\n",
    "from matplotlib.patches import Patch\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let´s first of all create the environment.\n",
    "We´ll use the Gymnasium´s Blackjack environment, we´ll allow natural blackjacks as well and the settings won´t follow the Sutton & Barto´s Book´s approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Blackjack-v1', sab=False, natural=True, render_mode='rgb_array') #We are not folllowing the default sutton and barto book settings, which are sab=True, natural=False, render_mode='human'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding and Observing the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation space: Tuple(Discrete(32), Discrete(11), Discrete(2))\n",
      "\n",
      "Action space: Discrete(2)\n",
      "\n",
      "Observation: (16, 1, False)\n",
      "\n",
      "Info: {}\n"
     ]
    }
   ],
   "source": [
    "#observation space is a tuple of 3 elements:\n",
    "#1. player's current sum (1-31)\n",
    "#2. dealer's face up card (1-10)\n",
    "#3. whether or not the player has a usable ace (0 or 1)\n",
    "\n",
    "done = False\n",
    "observation, info = env.reset() #get the first observation\n",
    "print(\"Observation space:\", env.observation_space) \n",
    "print(\"\\nAction space:\", env.action_space) #0: stick, 1: hit\n",
    "print(\"\\nObservation:\", observation) #Observation[1] is player's current sum, Observation[2] is dealer's face up card, Observation[3] is whether or not the player has a usable ace\n",
    "print(\"\\nInfo:\", info) #dealer´s first card\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let´s see how the agent behaves when making a step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**env.step(action)** returns: observation, reward, terminated, truncated, info\n",
    "\n",
    "**observation**: tuple of 3 elements (player's current sum, dealer's face up card, whether or not the player has a usable ace)\n",
    "\n",
    "**reward**: +1.5, +1, 0 or -1 (win, draw or loss), 1.5 if the player wins with a natural blackjack\n",
    "\n",
    "**terminated**: boolean (True if the episode is over)\n",
    "\n",
    "**truncated**: boolean (True if the episode is over because it reached the maximum number of steps)\n",
    "\n",
    "**info**: dictionary with additional information. We will not use this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random actions:\n",
      "Action: 0\n",
      "Observation: (19, 8, True)\n",
      "Reward: 1.0\n",
      "Terminated: True\n",
      "Truncated: False\n",
      "Info: {}\n",
      "\n",
      "Action: 1\n",
      "Observation: (10, 9, False)\n",
      "Reward: 0.0\n",
      "Terminated: False\n",
      "Truncated: False\n",
      "Info: {}\n",
      "\n",
      "Action: 0\n",
      "Observation: (7, 10, False)\n",
      "Reward: 1.0\n",
      "Terminated: True\n",
      "Truncated: False\n",
      "Info: {}\n",
      "\n",
      "Action: 0\n",
      "Observation: (16, 4, False)\n",
      "Reward: -1.0\n",
      "Terminated: True\n",
      "Truncated: False\n",
      "Info: {}\n",
      "\n",
      "Action: 1\n",
      "Observation: (13, 10, False)\n",
      "Reward: 0.0\n",
      "Terminated: False\n",
      "Truncated: False\n",
      "Info: {}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\neild\\Miniconda3\\envs\\pytorch-env\\lib\\site-packages\\gymnasium\\utils\\passive_env_checker.py:249: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "#sample random actions from the action space\n",
    "print(\"Random actions:\")\n",
    "for i in range(5):\n",
    "    env.reset() # reset the environment at the beginning of each iteration\n",
    "    action = env.action_space.sample()\n",
    "    print(\"Action:\", action)\n",
    "    observation, reward, terminated, truncated, info = env.step(action) #take a random action and observe the results of the action taken\n",
    "    print(\"Observation:\", observation) #Observation[1] is player's current sum, Observation[2] is dealer's face up card, Observation[3] is whether or not the player has a usable ace\n",
    "    print(\"Reward:\", reward) #reward is 1 if the player wins, 1.5 if player wins with natural blackjack (an usable ace and a 10), -1 if the player loses, and 0 if the game is a draw\n",
    "    print(\"Terminated:\", terminated)\n",
    "    print(\"Truncated:\", truncated)\n",
    "    print(\"Info:\", info)\n",
    "    print(\"\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let´s create a simple agent, the policy is very naive, if its own sum surpasses 20, sticks with its cards, if not, hits for more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBlackjackAgent:\n",
    "    def __init__(self): \n",
    "        pass\n",
    "\n",
    "    def play(self, obs):\n",
    "        return 0 if obs[0] >= 20 else 1 #stick if player's current sum is 20 or more, else hit\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will evaluate the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the hyperparameters\n",
    "n_episodes = 100\n",
    "\n",
    "#initialize the agent  \n",
    "agent = NaiveBlackjackAgent()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mneildlf\u001b[0m (\u001b[33mai42\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem at: C:\\Users\\neild\\AppData\\Local\\Temp\\ipykernel_21444\\2919867372.py 10 <module>\n"
     ]
    },
    {
     "ename": "MailboxError",
     "evalue": "transport failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMailboxError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\neild\\OneDrive\\Documentos\\ARTIFICIAL INTELLIGENCE (UAB)\\3º\\1st semester\\ML Paradigms\\Learn2Earn_RL\\Blackjack\\blackjack_naive_solver.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/neild/OneDrive/Documentos/ARTIFICIAL%20INTELLIGENCE%20%28UAB%29/3%C2%BA/1st%20semester/ML%20Paradigms/Learn2Earn_RL/Blackjack/blackjack_naive_solver.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# initialize wandb\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/neild/OneDrive/Documentos/ARTIFICIAL%20INTELLIGENCE%20%28UAB%29/3%C2%BA/1st%20semester/ML%20Paradigms/Learn2Earn_RL/Blackjack/blackjack_naive_solver.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m os\u001b[39m.\u001b[39menviron[\u001b[39m'\u001b[39m\u001b[39mWANDB_NOTEBOOK_NAME\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mblackjack_naive_solver.ipynb\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/neild/OneDrive/Documentos/ARTIFICIAL%20INTELLIGENCE%20%28UAB%29/3%C2%BA/1st%20semester/ML%20Paradigms/Learn2Earn_RL/Blackjack/blackjack_naive_solver.ipynb#X12sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m wandb\u001b[39m.\u001b[39;49minit(project\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mblackjack_naive\u001b[39;49m\u001b[39m\"\u001b[39;49m, entity\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mai42\u001b[39;49m\u001b[39m\"\u001b[39;49m) \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/neild/OneDrive/Documentos/ARTIFICIAL%20INTELLIGENCE%20%28UAB%29/3%C2%BA/1st%20semester/ML%20Paradigms/Learn2Earn_RL/Blackjack/blackjack_naive_solver.ipynb#X12sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfor\u001b[39;00m episode \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(n_episodes)):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/neild/OneDrive/Documentos/ARTIFICIAL%20INTELLIGENCE%20%28UAB%29/3%C2%BA/1st%20semester/ML%20Paradigms/Learn2Earn_RL/Blackjack/blackjack_naive_solver.ipynb#X12sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     obs, info \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mreset()\n",
      "File \u001b[1;32mc:\\Users\\neild\\Miniconda3\\envs\\pytorch-env\\lib\\site-packages\\wandb\\sdk\\wandb_init.py:1189\u001b[0m, in \u001b[0;36minit\u001b[1;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[0;32m   1187\u001b[0m     \u001b[39mif\u001b[39;00m logger \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1188\u001b[0m         logger\u001b[39m.\u001b[39mexception(\u001b[39mstr\u001b[39m(e))\n\u001b[1;32m-> 1189\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m   1190\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1191\u001b[0m     \u001b[39massert\u001b[39;00m logger\n",
      "File \u001b[1;32mc:\\Users\\neild\\Miniconda3\\envs\\pytorch-env\\lib\\site-packages\\wandb\\sdk\\wandb_init.py:1170\u001b[0m, in \u001b[0;36minit\u001b[1;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[0;32m   1168\u001b[0m except_exit \u001b[39m=\u001b[39m wi\u001b[39m.\u001b[39msettings\u001b[39m.\u001b[39m_except_exit\n\u001b[0;32m   1169\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1170\u001b[0m     run \u001b[39m=\u001b[39m wi\u001b[39m.\u001b[39;49minit()\n\u001b[0;32m   1171\u001b[0m     except_exit \u001b[39m=\u001b[39m wi\u001b[39m.\u001b[39msettings\u001b[39m.\u001b[39m_except_exit\n\u001b[0;32m   1172\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\neild\\Miniconda3\\envs\\pytorch-env\\lib\\site-packages\\wandb\\sdk\\wandb_init.py:815\u001b[0m, in \u001b[0;36m_WandbInit.init\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    813\u001b[0m run_start_handle \u001b[39m=\u001b[39m backend\u001b[39m.\u001b[39minterface\u001b[39m.\u001b[39mdeliver_run_start(run\u001b[39m.\u001b[39m_run_obj)\n\u001b[0;32m    814\u001b[0m \u001b[39m# TODO: add progress to let user know we are doing something\u001b[39;00m\n\u001b[1;32m--> 815\u001b[0m run_start_result \u001b[39m=\u001b[39m run_start_handle\u001b[39m.\u001b[39;49mwait(timeout\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m)\n\u001b[0;32m    816\u001b[0m \u001b[39mif\u001b[39;00m run_start_result \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    817\u001b[0m     run_start_handle\u001b[39m.\u001b[39mabandon()\n",
      "File \u001b[1;32mc:\\Users\\neild\\Miniconda3\\envs\\pytorch-env\\lib\\site-packages\\wandb\\sdk\\lib\\mailbox.py:281\u001b[0m, in \u001b[0;36mMailboxHandle.wait\u001b[1;34m(self, timeout, on_probe, on_progress, release, cancel)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_keepalive \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interface:\n\u001b[0;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interface\u001b[39m.\u001b[39m_transport_keepalive_failed():\n\u001b[1;32m--> 281\u001b[0m         \u001b[39mraise\u001b[39;00m MailboxError(\u001b[39m\"\u001b[39m\u001b[39mtransport failed\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    283\u001b[0m found, abandoned \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slot\u001b[39m.\u001b[39m_get_and_clear(timeout\u001b[39m=\u001b[39mwait_timeout)\n\u001b[0;32m    284\u001b[0m \u001b[39mif\u001b[39;00m found:\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Always update progress to 100% when done\u001b[39;00m\n",
      "\u001b[1;31mMailboxError\u001b[0m: transport failed"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "from gymnasium.wrappers import RecordEpisodeStatistics\n",
    "from IPython.display import clear_output\n",
    "import wandb\n",
    "import pygame\n",
    "import os\n",
    "\n",
    "# initialize wandb\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = 'blackjack_naive_solver.ipynb'\n",
    "wandb.init(project=\"blackjack_naive\", entity=\"ai42\") \n",
    "\n",
    "for episode in tqdm(range(n_episodes)):\n",
    "    obs, info = env.reset()\n",
    "    done = False\n",
    "    clear_output()\n",
    "    step = 0\n",
    "    \n",
    "    while not done:\n",
    "        action = agent.play(obs) #play according to the agent's policy: if obs[0] >= 20, stick(0), else hit(1)\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        step += 1\n",
    "        \n",
    "        frame = env.render()\n",
    "        plt.imshow(frame)\n",
    "        plt.axis('off')\n",
    "        #plt.show()\n",
    "        plt.title(\"Episode: {}, Step: {}\".format(episode, step))\n",
    "        \n",
    "        # Convert plot to image and log to wandb\n",
    "        plt.savefig('frame.png')\n",
    "        wandb.log({\"frame\": wandb.Image('frame.png')})\n",
    "        \n",
    "        #plt.pause(1)\n",
    "        plt.close()\n",
    "        \n",
    "        done = terminated or truncated\n",
    "        \n",
    "        print(\"Reward:\", reward)\n",
    "        print(\"Done:\", done)\n",
    "        print(\"Info:\", info)\n",
    "        wandb.log({\"reward\": reward})\n",
    "        print(\"\")\n",
    "        if done:\n",
    "            break\n",
    "    \n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1271219994.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[11], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    wandb login --relogin\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "wandb login --relogin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
