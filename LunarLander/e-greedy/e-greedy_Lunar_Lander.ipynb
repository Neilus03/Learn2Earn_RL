{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium in /home/ndelafuente/miniconda3/envs/pytorch-env/lib/python3.11/site-packages (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/ndelafuente/miniconda3/envs/pytorch-env/lib/python3.11/site-packages (from gymnasium) (1.26.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/ndelafuente/miniconda3/envs/pytorch-env/lib/python3.11/site-packages (from gymnasium) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /home/ndelafuente/miniconda3/envs/pytorch-env/lib/python3.11/site-packages (from gymnasium) (4.7.1)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /home/ndelafuente/miniconda3/envs/pytorch-env/lib/python3.11/site-packages (from gymnasium) (0.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from collections import deque\n",
    "import time\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from matplotlib.patches import Patch\n",
    "import os\n",
    "import pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device for training (GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the QNet class\n",
    "class QNet(nn.Module):\n",
    "    def __init__(self, env, lr=0.005, device=device):\n",
    "        super(QNet, self).__init__()\n",
    "        \n",
    "        # Set device for training (GPU if available)\n",
    "        self.device = device\n",
    "        \n",
    "        # Get state and action space dimensions\n",
    "        self.state_space_dim = env.observation_space.shape[0]\n",
    "        self.action_space_dim = env.action_space.n\n",
    "        \n",
    "        # Define possible actions\n",
    "        self.actions = torch.arange(self.action_space_dim).to(device)\n",
    "        \n",
    "        # Set learning rate\n",
    "        self.lr = lr\n",
    "        \n",
    "        # Define neural network architecture\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(self.state_space_dim, 16, bias=True),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(16, 32, bias=True),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(32, self.action_space_dim, bias=True),\n",
    "            nn.Softmax(dim=-1),\n",
    "            )\n",
    "        \n",
    "        # Define optimizer\n",
    "        self.optimizer = optim.Adam(self.net.parameters(), lr=self.lr)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Forward pass through the network\n",
    "        return self.net(x.to(self.device))\n",
    "    \n",
    "    \n",
    "    # Choose action based on epsilon-greedy policy\n",
    "    def get_action(self, state, epsilon=0.0):\n",
    "       \n",
    "        # Epsilon is the probability of choosing a random action\n",
    "        \n",
    "        if random.random() < epsilon:\n",
    "            \n",
    "            # Choose random action\n",
    "            return random.choice(self.actions)\n",
    "        \n",
    "        else: \n",
    "            \n",
    "            # Choose greedy action\n",
    "            with torch.no_grad(): # Don't track gradients\n",
    "                \n",
    "                # Get Q-values for each action\n",
    "                q_values = self.forward(state)\n",
    "                \n",
    "                # Choose best possible action\n",
    "                return torch.argmax(q_values).item()\n",
    "        \n",
    "    \n",
    "    def save_model(self, filename):\n",
    "        # Save model to file\n",
    "        torch.save(self.state_dict(), filename)\n",
    "    \n",
    "    def load_model(self, filename, device='cuda'):\n",
    "        # Load model from file\n",
    "        self.load_state_dict(torch.load(filename, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('LunarLander-v2', continuous=False)\n",
    "QNet = QNet(env).to(device)\n",
    "optimizer = optim.Adam(QNet.parameters(), lr=0.005)\n",
    "\n",
    "#HYPERPARAMETERS\n",
    "lr=0.005, \n",
    "gamma= 0.99, \n",
    "batch_size= 8,\n",
    "max_episodes= 5000\n",
    "\n",
    "epsilon_start= 1.0,\n",
    "epsilon_final= 0.01,\n",
    "epsilon_decay= 0.995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
